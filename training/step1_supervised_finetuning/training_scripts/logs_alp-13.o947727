[2023-04-27 15:15:44,867] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2023-04-27 15:15:44,935] [INFO] [runner.py:540:main] cmd = /home/bressekk/miniconda3/envs/deepspeed-chat/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py --data_path medalpaca/stack_exchange --model_name_or_path decapoda-research/llama-13b-hf --per_device_train_batch_size 16 --per_device_eval_batch_size 16 --gradient_accumulation_steps 8 --num_warmup_steps 1000 --max_seq_len 512 --learning_rate 5e-5 --weight_decay 0.1 --num_train_epochs 10 --wandb_run_name medalpaca-13b --lr_scheduler_type cosine --zero_stage 3 --output_dir /sc-projects/sc-proj-cc06-medbert/alpaca-zoo/in-training/medalpaca-deepspeed-13b --gradient_checkpointing True --seed 42 --deepspeed
[2023-04-27 15:15:53,910] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2023-04-27 15:15:53,910] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=8, node_rank=0
[2023-04-27 15:15:53,910] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2023-04-27 15:15:53,910] [INFO] [launch.py:247:main] dist_world_size=8
[2023-04-27 15:15:53,910] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2023-04-27 15:16:33,464] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-04-27 15:16:54,669] [INFO] [partition_parameters.py:436:__exit__] finished initializing model with 13.02B parameters
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combinationInstalled CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination

Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load fused_adam op: 0.6601998805999756 seconds
Time to load fused_adam op: 0.6135866641998291 seconds
Time to load fused_adam op: 0.7239785194396973 seconds
Time to load fused_adam op: 0.7229166030883789 seconds
Time to load fused_adam op: 0.7188646793365479 seconds
Time to load fused_adam op: 0.6227529048919678 seconds
Time to load fused_adam op: 0.7192976474761963 seconds
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load fused_adam op: 1.1818747520446777 seconds
[2023-04-27 15:17:43,055] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[2023-04-27 15:17:43,061] [INFO] [comm.py:580:init_distributed] Distributed backend already initialized
[2023-04-27 15:17:46,868] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-04-27 15:17:46,869] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-04-27 15:17:46,870] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-04-27 15:17:46,887] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2023-04-27 15:17:46,887] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2023-04-27 15:17:46,887] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2023-04-27 15:17:47,123] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-04-27 15:17:47,124] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.91 GB         CA 5.37 GB         Max_CA 5 GB 
[2023-04-27 15:17:47,124] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.63 GB, percent = 3.0%
[2023-04-27 15:17:47,126] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-04-27 15:17:47,126] [INFO] [stage3.py:114:__init__] Prefetch bucket size 30000000
ninja: no work to do.
Time to load utils op: 0.7415895462036133 seconds
Time to load utils op: 0.6068539619445801 seconds
Time to load utils op: 0.8203339576721191 seconds
Time to load utils op: 0.8208260536193848 seconds
Time to load utils op: 0.8220579624176025 seconds
Time to load utils op: 0.8220689296722412 seconds
Time to load utils op: 0.8240902423858643 seconds
Time to load utils op: 0.8247995376586914 seconds
[2023-04-27 15:17:47,874] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-04-27 15:17:47,875] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.07 GB         CA 5.37 GB         Max_CA 5 GB 
[2023-04-27 15:17:47,875] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.62 GB, percent = 3.0%
Parameter Offload: Total persistent parameters: 414720 in 81 params
[2023-04-27 15:17:48,027] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-04-27 15:17:48,028] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.07 GB         CA 5.37 GB         Max_CA 5 GB 
[2023-04-27 15:17:48,028] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.62 GB, percent = 3.0%
[2023-04-27 15:17:48,162] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-04-27 15:17:48,162] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.07 GB         CA 5.37 GB         Max_CA 5 GB 
[2023-04-27 15:17:48,163] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.62 GB, percent = 3.0%
[2023-04-27 15:17:50,430] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 2
[2023-04-27 15:17:50,431] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.07 GB         CA 3.07 GB         Max_CA 5 GB 
[2023-04-27 15:17:50,431] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 79.76 GB, percent = 4.0%
[2023-04-27 15:17:50,566] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-04-27 15:17:50,567] [INFO] [utils.py:786:see_memory_usage] MA 3.07 GB         Max_MA 3.07 GB         CA 3.07 GB         Max_CA 3 GB 
[2023-04-27 15:17:50,567] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 75.98 GB, percent = 3.8%
[2023-04-27 15:17:50,703] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-04-27 15:17:50,704] [INFO] [utils.py:786:see_memory_usage] MA 9.13 GB         Max_MA 10.29 GB         CA 11.0 GB         Max_CA 11 GB 
[2023-04-27 15:17:50,704] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 68.33 GB, percent = 3.4%
[2023-04-27 15:17:51,367] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-04-27 15:17:51,367] [INFO] [utils.py:786:see_memory_usage] MA 9.13 GB         Max_MA 9.13 GB         CA 11.0 GB         Max_CA 11 GB 
[2023-04-27 15:17:51,367] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.61 GB, percent = 3.0%
[2023-04-27 15:17:51,516] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-04-27 15:17:51,517] [INFO] [utils.py:786:see_memory_usage] MA 21.25 GB         Max_MA 24.99 GB         CA 26.87 GB         Max_CA 27 GB 
[2023-04-27 15:17:51,517] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.61 GB, percent = 3.0%
[2023-04-27 15:17:51,517] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Time to load utils op: 0.0024378299713134766 seconds
Time to load utils op: 0.002185344696044922 seconds
Time to load utils op: 0.004563808441162109 seconds
Time to load utils op: 0.005323886871337891 seconds
Time to load utils op: 0.005249500274658203 seconds
Time to load utils op: 0.0053708553314208984 seconds
Time to load utils op: 0.0047724246978759766 seconds
[2023-04-27 15:17:51,875] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-04-27 15:17:51,876] [INFO] [utils.py:786:see_memory_usage] MA 25.22 GB         Max_MA 25.83 GB         CA 32.3 GB         Max_CA 32 GB 
[2023-04-27 15:17:51,876] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.62 GB, percent = 3.0%
[2023-04-27 15:17:51,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2023-04-27 15:17:51,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-04-27 15:17:51,876] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f65dc482c70>
[2023-04-27 15:17:51,876] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.95)]
[2023-04-27 15:17:51,877] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-04-27 15:17:51,877] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-04-27 15:17:51,877] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   amp_params ................... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f65d0513400>
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   dump_state ................... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'min_scale': 1}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   fp16_enabled ................. True
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 8
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-04-27 15:17:51,878] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   pld_params ................... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   train_batch_size ............. 1024
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  16
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   world_size ................... 8
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=False
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-04-27 15:17:51,879] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-04-27 15:17:51,879] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 1.024000e+03, 
    "train_micro_batch_size_per_gpu": 16, 
    "steps_per_print": 10, 
    "zero_optimization": {
        "stage": 3, 
        "offload_param": {
            "device": "none"
        }, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "stage3_param_persistence_threshold": 1.000000e+04, 
        "stage3_max_live_parameters": 3.000000e+07, 
        "stage3_prefetch_bucket_size": 3.000000e+07, 
        "memory_efficient_linear": false
    }, 
    "fp16": {
        "enabled": true, 
        "loss_scale_window": 100
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": false, 
    "wall_clock_breakdown": false, 
    "hybrid_engine": {
        "enabled": false, 
        "inference_tp_size": 1, 
        "release_inference_cache": false, 
        "pin_parameters": true, 
        "tp_gather_partition_size": 8
    }
}
Time to load utils op: 0.0020411014556884766 seconds
[2023-04-27 15:18:52,538] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
[2023-04-27 15:19:34,720] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2023-04-27 15:20:16,869] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
[2023-04-27 15:20:59,046] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
[2023-04-27 15:21:41,182] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
[2023-04-27 15:22:23,239] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048
[2023-04-27 15:23:05,249] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, reducing to 1024
[2023-04-27 15:23:47,230] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024, reducing to 512
[2023-04-27 15:24:37,364] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 512, reducing to 256
[2023-04-27 15:25:19,159] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 128
[2023-04-27 15:25:19,159] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0], mom=[(0.9, 0.95)]
[2023-04-27 15:25:19,160] [INFO] [timer.py:199:stop] epoch=1/micro_step=15/global_step=10, RunningAvgSamplesPerSec=24.50803524486301, CurrSamplesPerSec=24.50941966371074, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 15:26:00,949] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 128, reducing to 64
[2023-04-27 15:26:42,626] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 64, reducing to 32
[2023-04-27 15:28:05,985] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32, reducing to 16
[2023-04-27 15:32:23,919] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=13, lr=[3.5000000000000004e-07], mom=[(0.9, 0.95)]
[2023-04-27 15:32:23,920] [INFO] [timer.py:199:stop] epoch=2/micro_step=30/global_step=20, RunningAvgSamplesPerSec=24.614193490854227, CurrSamplesPerSec=24.61198407946072, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 15:39:28,524] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=13, lr=[8.500000000000001e-07], mom=[(0.9, 0.95)]
[2023-04-27 15:39:28,525] [INFO] [timer.py:199:stop] epoch=3/micro_step=45/global_step=30, RunningAvgSamplesPerSec=24.647702735819998, CurrSamplesPerSec=24.617528086291472, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 15:46:32,689] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=13, lr=[1.35e-06], mom=[(0.9, 0.95)]
[2023-04-27 15:46:32,691] [INFO] [timer.py:199:stop] epoch=4/micro_step=60/global_step=40, RunningAvgSamplesPerSec=24.671123382764996, CurrSamplesPerSec=24.64825267292393, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 15:53:45,308] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=13, lr=[1.85e-06], mom=[(0.9, 0.95)]
[2023-04-27 15:53:45,311] [INFO] [timer.py:199:stop] epoch=6/micro_step=10/global_step=50, RunningAvgSamplesPerSec=24.704284468399134, CurrSamplesPerSec=24.572423817339832, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 16:00:50,501] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=13, lr=[2.35e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:00:50,502] [INFO] [timer.py:199:stop] epoch=7/micro_step=25/global_step=60, RunningAvgSamplesPerSec=24.699048178815765, CurrSamplesPerSec=24.604518429938608, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 16:07:53,516] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=13, lr=[2.8500000000000002e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:07:53,517] [INFO] [timer.py:199:stop] epoch=8/micro_step=40/global_step=70, RunningAvgSamplesPerSec=24.71431680676063, CurrSamplesPerSec=24.762074553691342, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 16:14:55,106] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=13, lr=[3.3500000000000005e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:14:55,107] [INFO] [timer.py:199:stop] epoch=9/micro_step=55/global_step=80, RunningAvgSamplesPerSec=24.73643761062969, CurrSamplesPerSec=24.770514837068866, MemAllocated=25.72GB, MaxMemAllocated=40.28GB
[2023-04-27 16:16:09,693] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442211
[2023-04-27 16:16:25,311] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442212
[2023-04-27 16:16:25,349] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442213
[2023-04-27 16:16:25,383] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442214
[2023-04-27 16:16:25,417] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442215
[2023-04-27 16:16:25,452] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442216
[2023-04-27 16:16:25,486] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442217
[2023-04-27 16:16:25,486] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2442218
[2023-04-27 16:16:25,521] [ERROR] [launch.py:434:sigkill_handler] ['/home/bressekk/miniconda3/envs/deepspeed-chat/bin/python', '-u', 'main.py', '--local_rank=7', '--data_path', 'medalpaca/stack_exchange', '--model_name_or_path', 'decapoda-research/llama-13b-hf', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '16', '--gradient_accumulation_steps', '8', '--num_warmup_steps', '1000', '--max_seq_len', '512', '--learning_rate', '5e-5', '--weight_decay', '0.1', '--num_train_epochs', '10', '--wandb_run_name', 'medalpaca-13b', '--lr_scheduler_type', 'cosine', '--zero_stage', '3', '--output_dir', '/sc-projects/sc-proj-cc06-medbert/alpaca-zoo/in-training/medalpaca-deepspeed-13b', '--gradient_checkpointing', 'True', '--seed', '42', '--deepspeed'] exits with return code = 2
