[2023-04-27 16:16:38,981] [WARNING] [runner.py:190:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2023-04-27 16:16:39,049] [INFO] [runner.py:540:main] cmd = /home/bressekk/miniconda3/envs/deepspeed-chat/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None main.py --data_path medalpaca/stack_exchange --model_name_or_path decapoda-research/llama-7b-hf --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --gradient_accumulation_steps 4 --num_warmup_steps 500 --max_seq_len 512 --learning_rate 5e-5 --weight_decay 0.1 --num_train_epochs 10 --wandb_run_name medalpaca-7b --lr_scheduler_type cosine --zero_stage 3 --output_dir /sc-projects/sc-proj-cc06-medbert/alpaca-zoo/in-training/medalpaca-deepspeed-7b --gradient_checkpointing True --seed 42 --deepspeed
[2023-04-27 16:16:46,465] [INFO] [launch.py:229:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2023-04-27 16:16:46,466] [INFO] [launch.py:235:main] nnodes=1, num_local_procs=8, node_rank=0
[2023-04-27 16:16:46,466] [INFO] [launch.py:246:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2023-04-27 16:16:46,466] [INFO] [launch.py:247:main] dist_world_size=8
[2023-04-27 16:16:46,466] [INFO] [launch.py:249:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2023-04-27 16:17:32,508] [INFO] [comm.py:586:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-04-27 16:17:47,105] [INFO] [partition_parameters.py:436:__exit__] finished initializing model with 6.74B parameters
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load fused_adam op: 0.6533310413360596 seconds
Installed CUDA version 11.3 does not match the version torch was compiled with 11.7 but since the APIs are compatible, accepting this combination
ninja: no work to do.
Time to load fused_adam op: 0.7108876705169678 seconds
[2023-04-27 16:18:23,236] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.9.0, git-hash=unknown, git-branch=unknown
[2023-04-27 16:18:23,241] [INFO] [comm.py:580:init_distributed] Distributed backend already initialized
Time to load fused_adam op: 1.4123904705047607 seconds
Time to load fused_adam op: 1.412961721420288 seconds
Time to load fused_adam op: 1.4177675247192383 seconds
Time to load fused_adam op: 1.4116768836975098 seconds
Time to load fused_adam op: 1.4115686416625977 seconds
Time to load fused_adam op: 1.4223356246948242 seconds
[2023-04-27 16:18:26,900] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-04-27 16:18:26,902] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-04-27 16:18:26,902] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-04-27 16:18:26,913] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = FusedAdam
[2023-04-27 16:18:26,913] [INFO] [utils.py:51:is_zero_supported_optimizer] Checking ZeRO support for optimizer=FusedAdam type=<class 'deepspeed.ops.adam.fused_adam.FusedAdam'>
[2023-04-27 16:18:26,913] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 3 optimizer
[2023-04-27 16:18:27,137] [INFO] [utils.py:785:see_memory_usage] Stage 3 initialize beginning
[2023-04-27 16:18:27,138] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 2.28 GB         CA 7.2 GB         Max_CA 7 GB 
[2023-04-27 16:18:27,138] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.51 GB, percent = 3.0%
[2023-04-27 16:18:27,140] [INFO] [stage3.py:113:__init__] Reduce bucket size 500,000,000
[2023-04-27 16:18:27,140] [INFO] [stage3.py:114:__init__] Prefetch bucket size 30000000
ninja: no work to do.
Time to load utils op: 0.6187527179718018 seconds
Time to load utils op: 0.6136620044708252 seconds
Time to load utils op: 0.6201658248901367 seconds
Time to load utils op: 0.6159164905548096 seconds
Time to load utils op: 0.6206099987030029 seconds
Time to load utils op: 0.6086575984954834 seconds
Time to load utils op: 0.6066610813140869 seconds
Time to load utils op: 0.5061397552490234 seconds
[2023-04-27 16:18:27,770] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2023-04-27 16:18:27,771] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 1.6 GB         CA 7.2 GB         Max_CA 7 GB 
[2023-04-27 16:18:27,771] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.51 GB, percent = 3.0%
Parameter Offload: Total persistent parameters: 266240 in 65 params
[2023-04-27 16:18:27,913] [INFO] [utils.py:785:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2023-04-27 16:18:27,914] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 1.6 GB         CA 7.2 GB         Max_CA 7 GB 
[2023-04-27 16:18:27,914] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.51 GB, percent = 3.0%
[2023-04-27 16:18:28,042] [INFO] [utils.py:785:see_memory_usage] Before creating fp16 partitions
[2023-04-27 16:18:28,042] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 1.6 GB         CA 7.2 GB         Max_CA 7 GB 
[2023-04-27 16:18:28,042] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.51 GB, percent = 3.0%
[2023-04-27 16:18:29,647] [INFO] [utils.py:785:see_memory_usage] After creating fp16 partitions: 1
[2023-04-27 16:18:29,648] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 1.6 GB         CA 1.6 GB         Max_CA 7 GB 
[2023-04-27 16:18:29,648] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 62.34 GB, percent = 3.1%
[2023-04-27 16:18:29,776] [INFO] [utils.py:785:see_memory_usage] Before creating fp32 partitions
[2023-04-27 16:18:29,776] [INFO] [utils.py:786:see_memory_usage] MA 1.6 GB         Max_MA 1.6 GB         CA 1.6 GB         Max_CA 2 GB 
[2023-04-27 16:18:29,777] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.5 GB, percent = 3.0%
[2023-04-27 16:18:29,939] [INFO] [utils.py:785:see_memory_usage] After creating fp32 partitions
[2023-04-27 16:18:29,940] [INFO] [utils.py:786:see_memory_usage] MA 4.74 GB         Max_MA 6.31 GB         CA 6.31 GB         Max_CA 6 GB 
[2023-04-27 16:18:29,940] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.5 GB, percent = 3.0%
[2023-04-27 16:18:30,068] [INFO] [utils.py:785:see_memory_usage] Before initializing optimizer states
[2023-04-27 16:18:30,069] [INFO] [utils.py:786:see_memory_usage] MA 4.74 GB         Max_MA 4.74 GB         CA 6.31 GB         Max_CA 6 GB 
[2023-04-27 16:18:30,069] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.5 GB, percent = 3.0%
[2023-04-27 16:18:30,208] [INFO] [utils.py:785:see_memory_usage] After initializing optimizer states
[2023-04-27 16:18:30,209] [INFO] [utils.py:786:see_memory_usage] MA 11.02 GB         Max_MA 14.15 GB         CA 15.73 GB         Max_CA 16 GB 
[2023-04-27 16:18:30,209] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.5 GB, percent = 3.0%
[2023-04-27 16:18:30,209] [INFO] [stage3.py:366:_setup_for_real_optimizer] optimizer state initialized
Time to load utils op: 0.002687692642211914 seconds
Time to load utils op: 0.002666950225830078 seconds
Time to load utils op: 0.002989530563354492 seconds
Time to load utils op: 0.0028371810913085938 seconds
Time to load utils op: 0.002989530563354492 seconds
Time to load utils op: 0.0025196075439453125 seconds
Time to load utils op: 0.0018885135650634766 seconds
[2023-04-27 16:18:30,470] [INFO] [utils.py:785:see_memory_usage] After initializing ZeRO optimizer
[2023-04-27 16:18:30,470] [INFO] [utils.py:786:see_memory_usage] MA 13.52 GB         Max_MA 14.0 GB         CA 15.81 GB         Max_CA 16 GB 
[2023-04-27 16:18:30,470] [INFO] [utils.py:793:see_memory_usage] CPU Virtual Memory:  used = 59.51 GB, percent = 3.0%
[2023-04-27 16:18:30,471] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = FusedAdam
[2023-04-27 16:18:30,471] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2023-04-27 16:18:30,471] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <torch.optim.lr_scheduler.LambdaLR object at 0x7f2c86513820>
[2023-04-27 16:18:30,471] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.95)]
[2023-04-27 16:18:30,472] [INFO] [config.py:953:print] DeepSpeedEngine configuration:
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   amp_enabled .................. False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   amp_params ................... False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   bfloat16_enabled ............. False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   checkpoint_parallel_write_pipeline  False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   checkpoint_tag_validation_enabled  True
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   checkpoint_tag_validation_fail  False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f2c4c65cdf0>
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   communication_data_type ...... None
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   curriculum_enabled_legacy .... False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   curriculum_params_legacy ..... False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   data_efficiency_enabled ...... False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   dataloader_drop_last ......... False
[2023-04-27 16:18:30,472] [INFO] [config.py:957:print]   disable_allgather ............ False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   dump_state ................... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 100, 'delayed_shift': 2, 'min_scale': 1}
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_enabled ........... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_gas_boundary_resolution  1
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_layer_num ......... 0
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_max_iter .......... 100
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_stability ......... 1e-06
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_tol ............... 0.01
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   eigenvalue_verbose ........... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   elasticity_enabled ........... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   fp16_auto_cast ............... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   fp16_enabled ................. True
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   fp16_master_weights_and_gradients  False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   global_rank .................. 0
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   grad_accum_dtype ............. None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   gradient_accumulation_steps .. 4
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   gradient_clipping ............ 1.0
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   gradient_predivide_factor .... 1.0
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   initial_dynamic_scale ........ 65536
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   load_universal_checkpoint .... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   loss_scale ................... 0
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   memory_breakdown ............. False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   optimizer_legacy_fusion ...... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   optimizer_name ............... None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   optimizer_params ............. None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   pld_enabled .................. False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   pld_params ................... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   prescale_gradients ........... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   scheduler_name ............... None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   scheduler_params ............. None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   sparse_attention ............. None
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   sparse_gradients_enabled ..... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   steps_per_print .............. 10
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   train_batch_size ............. 1024
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   train_micro_batch_size_per_gpu  32
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   use_node_local_storage ....... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   wall_clock_breakdown ......... False
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   world_size ................... 8
[2023-04-27 16:18:30,473] [INFO] [config.py:957:print]   zero_allow_untested_optimizer  False
[2023-04-27 16:18:30,474] [INFO] [config.py:957:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=30000000 param_persistence_threshold=10000 model_persistence_threshold=sys.maxsize max_live_parameters=30000000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False memory_efficient_linear=False
[2023-04-27 16:18:30,474] [INFO] [config.py:957:print]   zero_enabled ................. True
[2023-04-27 16:18:30,474] [INFO] [config.py:957:print]   zero_force_ds_cpu_optimizer .. True
[2023-04-27 16:18:30,474] [INFO] [config.py:957:print]   zero_optimization_stage ...... 3
[2023-04-27 16:18:30,474] [INFO] [config.py:943:print_user_config]   json = {
    "train_batch_size": 1.024000e+03, 
    "train_micro_batch_size_per_gpu": 32, 
    "steps_per_print": 10, 
    "zero_optimization": {
        "stage": 3, 
        "offload_param": {
            "device": "none"
        }, 
        "offload_optimizer": {
            "device": "none"
        }, 
        "stage3_param_persistence_threshold": 1.000000e+04, 
        "stage3_max_live_parameters": 3.000000e+07, 
        "stage3_prefetch_bucket_size": 3.000000e+07, 
        "memory_efficient_linear": false
    }, 
    "fp16": {
        "enabled": true, 
        "loss_scale_window": 100
    }, 
    "gradient_clipping": 1.0, 
    "prescale_gradients": false, 
    "wall_clock_breakdown": false, 
    "hybrid_engine": {
        "enabled": false, 
        "inference_tp_size": 1, 
        "release_inference_cache": false, 
        "pin_parameters": true, 
        "tp_gather_partition_size": 8
    }
}
Time to load utils op: 0.0020241737365722656 seconds
[2023-04-27 16:19:09,582] [INFO] [loss_scaler.py:188:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1
[2023-04-27 16:19:32,158] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768
[2023-04-27 16:19:54,804] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384
[2023-04-27 16:20:17,468] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192
[2023-04-27 16:20:40,142] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192, reducing to 4096
[2023-04-27 16:21:02,788] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096, reducing to 2048
[2023-04-27 16:21:25,413] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048, reducing to 1024
[2023-04-27 16:21:47,995] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024, reducing to 512
[2023-04-27 16:22:12,366] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 512, reducing to 256
[2023-04-27 16:22:34,875] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256, reducing to 128
[2023-04-27 16:22:34,876] [INFO] [logging.py:96:log_dist] [Rank 0] step=10, skipped=10, lr=[0.0], mom=[(0.9, 0.95)]
[2023-04-27 16:22:34,876] [INFO] [timer.py:199:stop] epoch=1/micro_step=7/global_step=10, RunningAvgSamplesPerSec=46.251521934340175, CurrSamplesPerSec=45.50959110015077, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:24:04,865] [INFO] [loss_scaler.py:181:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 128, reducing to 64
[2023-04-27 16:26:21,429] [INFO] [logging.py:96:log_dist] [Rank 0] step=20, skipped=11, lr=[9e-07], mom=[(0.9, 0.95)]
[2023-04-27 16:26:21,430] [INFO] [timer.py:199:stop] epoch=2/micro_step=14/global_step=20, RunningAvgSamplesPerSec=46.29705699859732, CurrSamplesPerSec=45.62373238221379, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:30:08,161] [INFO] [logging.py:96:log_dist] [Rank 0] step=30, skipped=11, lr=[1.9e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:30:08,162] [INFO] [timer.py:199:stop] epoch=3/micro_step=21/global_step=30, RunningAvgSamplesPerSec=46.298523901269455, CurrSamplesPerSec=45.47950402629568, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:33:55,003] [INFO] [logging.py:96:log_dist] [Rank 0] step=40, skipped=11, lr=[2.9e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:33:55,004] [INFO] [timer.py:199:stop] epoch=4/micro_step=28/global_step=40, RunningAvgSamplesPerSec=46.29451189532344, CurrSamplesPerSec=45.52540137995697, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:37:43,183] [INFO] [logging.py:96:log_dist] [Rank 0] step=50, skipped=11, lr=[3.9e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:37:43,184] [INFO] [timer.py:199:stop] epoch=6/micro_step=2/global_step=50, RunningAvgSamplesPerSec=46.47329286763175, CurrSamplesPerSec=54.59389442149365, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:41:29,377] [INFO] [logging.py:96:log_dist] [Rank 0] step=60, skipped=11, lr=[4.9000000000000005e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:41:29,378] [INFO] [timer.py:199:stop] epoch=7/micro_step=9/global_step=60, RunningAvgSamplesPerSec=46.46314591908341, CurrSamplesPerSec=45.65989890385535, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:45:15,441] [INFO] [logging.py:96:log_dist] [Rank 0] step=70, skipped=11, lr=[5.9e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:45:15,442] [INFO] [timer.py:199:stop] epoch=8/micro_step=16/global_step=70, RunningAvgSamplesPerSec=46.45980003496035, CurrSamplesPerSec=45.68596240834656, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:49:01,459] [INFO] [logging.py:96:log_dist] [Rank 0] step=80, skipped=11, lr=[6.900000000000001e-06], mom=[(0.9, 0.95)]
[2023-04-27 16:49:01,460] [INFO] [timer.py:199:stop] epoch=9/micro_step=23/global_step=80, RunningAvgSamplesPerSec=46.45859560688526, CurrSamplesPerSec=45.69570421148648, MemAllocated=14.51GB, MaxMemAllocated=33.87GB
[2023-04-27 16:50:01,559] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621861
[2023-04-27 16:50:03,959] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621862
[2023-04-27 16:50:04,002] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621863
[2023-04-27 16:50:04,038] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621864
[2023-04-27 16:50:04,038] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621865
[2023-04-27 16:50:04,073] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621866
[2023-04-27 16:50:04,108] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621867
[2023-04-27 16:50:04,143] [INFO] [launch.py:428:sigkill_handler] Killing subprocess 2621868
[2023-04-27 16:50:04,178] [ERROR] [launch.py:434:sigkill_handler] ['/home/bressekk/miniconda3/envs/deepspeed-chat/bin/python', '-u', 'main.py', '--local_rank=7', '--data_path', 'medalpaca/stack_exchange', '--model_name_or_path', 'decapoda-research/llama-7b-hf', '--per_device_train_batch_size', '32', '--per_device_eval_batch_size', '32', '--gradient_accumulation_steps', '4', '--num_warmup_steps', '500', '--max_seq_len', '512', '--learning_rate', '5e-5', '--weight_decay', '0.1', '--num_train_epochs', '10', '--wandb_run_name', 'medalpaca-7b', '--lr_scheduler_type', 'cosine', '--zero_stage', '3', '--output_dir', '/sc-projects/sc-proj-cc06-medbert/alpaca-zoo/in-training/medalpaca-deepspeed-7b', '--gradient_checkpointing', 'True', '--seed', '42', '--deepspeed'] exits with return code = 1
